{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tky_data_path = '/dataset_TSMC2014_TKY.txt'\n",
    "tky_data = pd.read_csv(tky_data_path, delimiter=\"\\t\", header=None, names=[\"user_id\", \"venue_id\", \"venue_category\", \"venue_category_name\", \"latitude\", \"longitude\", \"timezone_offset\", \"utc_time\"], encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_data_path = '/dataset_TSMC2014_NYC.txt'\n",
    "nyc_data = pd.read_csv(nyc_data_path, delimiter=\"\\t\", header=None, names=[\"user_id\", \"venue_id\", \"venue_category\", \"venue_category_name\", \"latitude\", \"longitude\", \"timezone_offset\", \"utc_time\"], encoding='ISO-8859-1')\n",
    "\n",
    "nyc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "class PredictionEvaluator_2:\n",
    "    # Compile the regex pattern once as a class attribute for efficiency\n",
    "    ALPHANUMERIC_PATTERN = re.compile(r'[a-f0-9]{24}')\n",
    "\n",
    "    def __init__(self, folder_path):\n",
    "        # Constructor to initialize the folder path and load data\n",
    "        self.folder_path = folder_path\n",
    "        self.combined_data = {}  # Dictionary to hold all combined data\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load JSON files from the specified folder path.\"\"\"\n",
    "    # Iterate over files in the folder\n",
    "        for index, file_name in enumerate(os.listdir(self.folder_path), start=1):\n",
    "            if file_name.endswith(\".json\"):\n",
    "                file_path = os.path.join(self.folder_path, file_name)\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as file:\n",
    "                        # Check if file is not empty\n",
    "                        if os.stat(file_path).st_size > 0:\n",
    "                            # Load data from each JSON file\n",
    "                            self.combined_data[str(index)] = json.load(file)\n",
    "                        else:\n",
    "                            print(f\"Skipped empty file: {file_name}\")\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing JSON file {file_name}: {e}\")\n",
    "\n",
    "    @classmethod\n",
    "    def extract_alphanumeric_codes(cls, text):\n",
    "        \"\"\"Extract alphanumeric codes using regex.\"\"\"\n",
    "        # Use the compiled regex pattern to find all matches\n",
    "        return cls.ALPHANUMERIC_PATTERN.findall(text)\n",
    "\n",
    "    def extract_combined_response_data(self):\n",
    "        \"\"\"Extract prediction codes from the loaded dataset.\"\"\"\n",
    "        total_outputs = sum('output' in entry for entry in self.combined_data.values())\n",
    "        all_codes = {}\n",
    "\n",
    "        for key, entry in self.combined_data.items():\n",
    "            if 'output' in entry:\n",
    "                if 'raw_response' in entry['output']:\n",
    "                    # Extract codes from raw_response\n",
    "                    extracted_codes = self.extract_alphanumeric_codes(entry['output']['raw_response'])\n",
    "                    all_codes[key] = extracted_codes if extracted_codes else [entry['output']]\n",
    "                else:\n",
    "                    # If no raw_response, store the output directly\n",
    "                    all_codes[key] = [entry['output']]\n",
    "\n",
    "        return total_outputs, all_codes\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prediction_values(predictions):\n",
    "        \"\"\"Extract prediction values from different prediction formats.\"\"\"\n",
    "        prediction_values = []\n",
    "\n",
    "        if isinstance(predictions, list):\n",
    "            for pred in predictions:\n",
    "                if isinstance(pred, dict) and 'prediction' in pred:\n",
    "                    # Extract prediction values from dict format\n",
    "                    prediction_values.extend([p.lower() for p in pred['prediction'] if isinstance(p, str)])\n",
    "                elif isinstance(pred, str):\n",
    "                    # Handle string format predictions\n",
    "                    prediction_values.append(pred.lower())\n",
    "\n",
    "        return prediction_values\n",
    "\n",
    "    def compute_combined_top_accuracies(self):\n",
    "        \"\"\"Compute top-1, top-3, and top-5 accuracies.\"\"\"\n",
    "        total_outputs, extracted_codes = self.extract_combined_response_data()\n",
    "        correct_top_1 = 0  \n",
    "        correct_top_3 = 0  \n",
    "        correct_top_5 = 0  \n",
    "\n",
    "        for key, predictions in extracted_codes.items():\n",
    "            if key in self.combined_data:\n",
    "                true_value = self.combined_data[key]['true'].lower()\n",
    "                prediction_values = [pred.lower() for pred in self.get_prediction_values(predictions)]\n",
    "\n",
    "                # Check if true value matches predictions for different top-n accuracies\n",
    "                if true_value in prediction_values:\n",
    "                    if true_value == prediction_values[0]:  # Top-1 accuracy\n",
    "                        correct_top_1 += 1\n",
    "                    if true_value in prediction_values[:3]:  # Top-3 accuracy\n",
    "                        correct_top_3 += 1\n",
    "                    if true_value in prediction_values[:5]:  # Top-5 accuracy\n",
    "                        correct_top_5 += 1\n",
    "\n",
    "        # Calculate accuracies, handling division by zero\n",
    "        accuracy_top_1 = correct_top_1 / total_outputs if total_outputs else 0\n",
    "        accuracy_top_3 = correct_top_3 / total_outputs if total_outputs else 0\n",
    "        accuracy_top_5 = correct_top_5 / total_outputs if total_outputs else 0\n",
    "\n",
    "        return accuracy_top_1, accuracy_top_3, accuracy_top_5\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_stays(input_str):\n",
    "        \"\"\"Extract historical and context stays from the input string.\"\"\"\n",
    "        # Initialize lists for historical and context stays\n",
    "        historical_stays = []\n",
    "        context_stays = []\n",
    "\n",
    "        # Extracting stays using string manipulation\n",
    "        historical_start = input_str.find('<historical_stays>:') + len('<historical_stays>:')\n",
    "        historical_end = input_str.find('<context_stays>:')\n",
    "        context_start = historical_end + len('<context_stays>:')\n",
    "        context_end = input_str.find('<target_stay>:')\n",
    "\n",
    "        historical_stays_str = input_str[historical_start:historical_end].strip()\n",
    "        context_stays_str = input_str[context_start:context_end].strip()\n",
    "\n",
    "        try:\n",
    "            # Convert extracted string to lists\n",
    "            historical_stays = eval(historical_stays_str)\n",
    "            context_stays = eval(context_stays_str)\n",
    "        except SyntaxError:\n",
    "            # Handle any parsing error\n",
    "            pass\n",
    "\n",
    "        return historical_stays, context_stays\n",
    "\n",
    "    @staticmethod\n",
    "    def get_predictions_from_entry(entry):\n",
    "        predictions = []\n",
    "\n",
    "        # Extracting predictions from raw_response\n",
    "        output_data = entry.get(\"output\", {})\n",
    "        raw_response = output_data.get(\"raw_response\", \"\")\n",
    "        raw_response_predictions = re.findall(r'\"prediction\": \\[(.*?)\\]', raw_response)\n",
    "        if raw_response_predictions:\n",
    "            try:\n",
    "                predictions.extend(json.loads(f\"[{raw_response_predictions[0]}]\"))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON in raw_response_predictions: {e}, skip it \\n\")  #DA RISOLVERE\n",
    "\n",
    "        #extracting predictions directly from the prediction field\n",
    "        direct_predictions = output_data.get(\"prediction\", [])\n",
    "        if isinstance(direct_predictions, list):\n",
    "            predictions.extend(direct_predictions)\n",
    "        elif isinstance(direct_predictions, str):\n",
    "            predictions.append(direct_predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def is_prediction_in_input(entry, historical_stays, context_stays):\n",
    "        \"\"\"Check if any prediction is in historical or context stays.\"\"\"\n",
    "        predictions = PredictionEvaluator_2.get_predictions_from_entry(entry)\n",
    "\n",
    "        # Check if any prediction is in historical_stays or context_stays\n",
    "        for prediction in predictions:\n",
    "            if any(prediction in stay for stay in historical_stays) or any(prediction in stay for stay in context_stays):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def evaluate_predictions(self):\n",
    "        \"\"\"Evaluate predictions in the dataset.\"\"\"\n",
    "        total_entries = len(self.combined_data)\n",
    "        entries_with_prediction_in_input = 0\n",
    "        remaining_percentage_ids = []\n",
    "\n",
    "        # Iterate through data and check if predictions are in input\n",
    "        for key, entry in self.combined_data.items():\n",
    "            historical_stays, context_stays = self.extract_stays(entry['input'])\n",
    "            prediction_in_input = self.is_prediction_in_input(entry, historical_stays, context_stays)\n",
    "\n",
    "            if prediction_in_input:\n",
    "                entries_with_prediction_in_input += 1\n",
    "            else:\n",
    "                remaining_percentage_ids.append(key)\n",
    "\n",
    "        # Calculate percentages\n",
    "        percentage_with_prediction = (entries_with_prediction_in_input / total_entries) * 100\n",
    "        remaining_percentage = 100 - percentage_with_prediction\n",
    "\n",
    "        return percentage_with_prediction, remaining_percentage, remaining_percentage_ids\n",
    "\n",
    "    def print_predictions_for_ids(self, ids, df, column_to_check):\n",
    "        \"\"\"Print predictions for specified IDs.\"\"\"\n",
    "        total_entries = len(ids)\n",
    "        correct_matches_with_true_value = 0\n",
    "        correct_matches_with_df_column = 0\n",
    "        unique_predictions = set()\n",
    "\n",
    "        for entry_id in ids:\n",
    "            if entry_id in self.combined_data:\n",
    "                entry = self.combined_data[entry_id]\n",
    "                predictions = self.get_predictions_from_entry(entry)\n",
    "\n",
    "                if not predictions:\n",
    "                    continue\n",
    "\n",
    "                true_value = entry.get(\"true\", \"\").lower()\n",
    "\n",
    "                print(f\"Entry ID: {entry_id}\")\n",
    "                print(f\"True Value: {true_value}\")\n",
    "                print(f\"Predictions: {predictions}\")\n",
    "\n",
    "                # handle both strings and dictionaries\n",
    "                prediction_values = []\n",
    "                for prediction in predictions:\n",
    "                    if isinstance(prediction, dict) and 'place_id' in prediction:\n",
    "                        prediction_values.append(prediction['place_id'].lower())\n",
    "                    elif isinstance(prediction, str):\n",
    "                        prediction_values.append(prediction.lower())\n",
    "\n",
    "                match_with_true_value = any(true_value == prediction for prediction in prediction_values)\n",
    "                print(f\"Match with True Value: {match_with_true_value}\")\n",
    "\n",
    "                if match_with_true_value:\n",
    "                    correct_matches_with_true_value += 1\n",
    "\n",
    "                # Check if any prediction matches any value in the specified DataFrame column\n",
    "                values_to_check = set(df[column_to_check].str.lower())\n",
    "                matching_predictions_df = [prediction for prediction in prediction_values if prediction in values_to_check]\n",
    "                match_with_df_column = bool(matching_predictions_df)\n",
    "                print(f\"Match with {column_to_check} Column: {match_with_df_column}\")\n",
    "\n",
    "                if match_with_df_column:\n",
    "                    correct_matches_with_df_column += 1\n",
    "                    print(f\"Matching Predictions in {column_to_check} Column: {matching_predictions_df}\")\n",
    "                    unique_predictions.update(matching_predictions_df)\n",
    "\n",
    "                print(\"------------------------\")\n",
    "            else:\n",
    "                print(f\"Entry with ID {entry_id} not found in the JSON data.\")\n",
    "\n",
    "        # Calculate and print percentage of correct matches\n",
    "        percentage_correct_matches_with_true_value = (correct_matches_with_true_value / total_entries) * 100\n",
    "        print(f\"Percentage of Matches with True Value: {percentage_correct_matches_with_true_value:.2f}%\")\n",
    "\n",
    "        percentage_correct_matches_with_df_column = (correct_matches_with_df_column / total_entries) * 100\n",
    "        print(f\"Percentage of Matches with {column_to_check} Column: {percentage_correct_matches_with_df_column:.2f}%\")\n",
    "\n",
    "        print(f\"Unique Predictions: {list(unique_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = '/gpt35turbo/1/'  # path with all the JSONs of the model to test\n",
    "evaluator_2 = PredictionEvaluator_2(folder_path)\n",
    "\n",
    "# Evaluate predictions\n",
    "accuracy_top_1, accuracy_top_3, accuracy_top_5 = evaluator_2.compute_combined_top_accuracies()\n",
    "print(f\"Top-1 Accuracy: {accuracy_top_1 * 100:.2f}%\")\n",
    "print(f\"Top-3 Accuracy: {accuracy_top_3 * 100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {accuracy_top_5 * 100:.2f}%\")\n",
    "percentage_with_prediction, remaining_percentage, remaining_ids = evaluator_2.evaluate_predictions()\n",
    "print(f\"Percentage of entries with prediction in input: {percentage_with_prediction:.2f}%\")\n",
    "print(f\"Remaining Percentage: {remaining_percentage:.2f}%\")\n",
    "print(f\"IDs with Remaining Percentage: {remaining_ids}\")\n",
    "evaluator_2.print_predictions_for_ids(remaining_ids, nyc_data, 'venue_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
